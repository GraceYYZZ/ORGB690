Question 1

We believe that all studies conducted by Google fall under the same
design: NR O1 X O2, where O1 is a “score” before change in policy, X is 
the change in policy, and O2 is the “score” after change in policy. 
Here, the word “score” can refer to different metrics, such as employee
attrition, hiring speed, management effectiveness, and so on. This
depends on the specific context and policy implementation. Moreover,
across all studies, we observe a lack of control group in their
experiments. One possible way to address this problem would be to
implement the policies only for some geographical locations or business
divisions in the company. Overall, we have identified six examples where
this design is used.  

1. Maternity and paternity leave plans 
After the implementation of a five-month maternity
leave plan, the attrition rate for new mothers fell to the average rate
for the rest of the firm, constituting a 50 percent reduction. 


2. Optimal number of interviews
Based on their data, Google changed the number of interviews per
candidate to four. As a result, interview times shrunk, and Google’s
hiring sped up. 

3. Middle managers 
Google began coaching unsuccessful managers based on employees’ bullet point characterizations of
successful managers. The collective feedback scores for managers have
improved every year since. 

4. How to give an employee more money 
In the fall of 2010, Google’s CEO announced a 10 percent salary increase for
all employees. The reaction was overwhelmingly positive, and some even
cited it as their happiest moment at Google. Attrition to competitors
declined as a result. 

5. Saving for 401k 

After receiving more reminders with more aggressive savings goals, employees tended to put more money
in their 401k accounts, even if they did not reach the goal. 

6. Lunch
After stocking cafeterias with 8-inch plates alongside 12-inch plates,
Google observed that people tended to eat smaller, healthier portions.

Question 2

In the analysis below, we examine five steps that the experimenters took
to improve the research design. We observe that the threat in four of
these cases (all except the second one) is selection, and the
experimenters aimed to mitigate it as much as possible. 

First, they used 200 identical wallets and dropped them in each of the 20 cities to
eliminate the factor of different wallets potentially affecting people's
willingness to return them. This step addresses the threat of
confounding variables, where an uncontrolled variable may influence the
outcome and lead to incorrect conclusions. By using identical wallets,
the experimenters ensure that any differences in the wallets' return
rates are due to the independent variable being tested, which is
people’s honesty across different demographic groups. 

Second, the experimenters added identical IDs, US and Filipino dollars, and pictures
of a baby and a puppy to make the wallet look like it had a lot of money
and it had sentimental value to the owner. This step aims to limit the
reasons why participants may not return the wallet by making it less
likely for them to believe the wallet was fake or not worth returning.
The threat here can be categorized as attrition. 

Third, the experimenters randomly dropped half of the wallets in high-income areas
and the other half in low-income areas. This step tests whether a
person's wealthiness affects their honesty. 

Fourth, the experimenters dropped two of the ten wallets in the men's restroom and two in the
women's restroom. This step aims to eliminate the effect of certain
places typically having more men, such as sports bars and hardware
stores. It aims to test if gender affects honesty. 

Finally, the experimenters tested four cities with populations of only around a
thousand people, while the rest were the largest cities in North
America. This step is useful for comparing the results from small cities versus big cities.